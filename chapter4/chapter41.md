# 数据处理

数据处理是数据分析，及后续数据挖掘中最重要的部分。
数据处理： 1. 可以提高数据的质量。2。能够较好支持数据分析。 

数据处理包括：
数据清洗、数据抽取、数据交换 和数据计算

## 1 数据清洗 
### 重复值的处理

1) DataFrame 中的 duplicated 方法检查是否有重复行。

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({'age':pd.Series([26, 33, 78, 23, 26]),
                  'name':pd.Series(['aa', 'bb', 'cc', 'dd', 'aa'])})
print(df)
'''
   age name
0   26   aa
1   33   bb
2   78   cc
3   23   dd
4   26   aa
'''

print(df.duplicated())
'''
print(df['name'].duplicated()) # name 这一列是不是有重复；
0    False
1    False
2    False
3    False
4     True # 最后一行是重复的。
'''
df = df.drop_duplicates()
print(df)

'''
   age name
0   26   aa
1   33   bb
2   78   cc
3   23   dd
'''
```
通过去重， 可以有效减少重复数据带来数据分析的错误。

### 缺失值处理
假设有下列有缺失值矩阵

```Python
import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randint(low=2, high=10, size=(5, 6)))
print(df)
df.iloc[2:4, 1:3] = np.nan # 该矩阵的 第1行~第2行， 第0列到第2列 改为NAN
print(df)
'''
   0  1  2  3  4  5
0  9  9  6  7  3  8
1  6  8  3  4  5  2
2  5  9  4  4  4  7
3  3  3  2  8  8  4
4  4  3  6  4  7  4
============================

   0    1    2  3  4  5
0  9  9.0  6.0  7  3  8
1  6  8.0  3.0  4  5  2
2  5  NaN  NaN  4  4  7
3  3  NaN  NaN  8  8  4
4  4  3.0  6.0  4  7  4
'''
```
在该矩阵[2:4,1:3]处有缺失值。 

我们有几种处理方法：
#### 1. 数据补齐
```Python
df = df.fillna(method='pad')
# 用前一个数值填入
df = df.fillna(method='bfill')
# 用后一个数值填入
df = df.fillna(df.mean())
# 用均值来填补

df = df.fillna(df.mean()['A列':'B列'])
# 用B列的均值来代替A列的缺失值。
```

#### 2. 数据删除
如果在海量的数据前提下， 如果通过df.isnull()来判断该数据中缺失值较少。 删除
不影响整体数据质量情况下，我们可以选择删除存在缺失值的行

```Python
df.dropna()
```

## 2. 数据抽取

数据抽取指的是抽出指定位置的数据做成新的数据。 

### 1. head(),tail() 函数  前 5 行 和后 5 行

```Python
import pandas as pd
dt = pd.read_csv(r'k:\rz.csv', sep=',')
print(dt.head())
print(dt.tail())
```
抽取该数据集中的前5条或者后5条记录。

### 2. slice()函数 指定位置的数据做成新的列。




```Python

import pandas as pd

my_data = pd.read_excel(r'd:\textfiles\i_nuc.xls', sheet_name='Sheet4')
#读取 i_nuc.xls 中表 Sheet4


my_data = my_data.fillna(method='bfill')
# 补全
my_data['电话'] = my_data['电话'].astype(str)
brands = my_data['电话'].str.slice(0, 3)
areas = my_data['电话'].str.slice(3, 7)
tells = my_data['电话'].str.slice(7, 11)
#分割

new_data = pd.concat([my_data, brands, areas, tells], axis=1)
#在表中创建新列  可以试试axis=0的结果。
print(new_data)
[output]
            学号             电话                 IP   电话    电话    电话
0   2308024241  18922254812.0      221.205.98.55  189  2225  4812
1   2308024244  13522255003.0    183.184.226.205  135  2225  5003
2   2308024251  13422259938.0      221.205.98.55  134  2225  9938
3   2308024249  18822256753.0      222.31.51.200  188  2225  6753
4   2308024219  18922253721.0       120.207.64.3  189  2225  3721
5   2308024201  13822254373.0      222.31.51.200  138  2225  4373
6   2308024347  13822254373.0      222.31.59.220  138  2225  4373
7   2308024307  13322252452.0  221.205.98.55      133  2225  2452
8   2308024326  18922257681.0     183.184.230.38  189  2225  7681
9   2308024320  13322252452.0  221.205.98.55      133  2225  2452
10  2308024342  18922257681.0     183.184.230.38  189  2225  7681
11  2308024310  19934210999.0     183.184.230.39  199  3421  0999
12  2308024435  19934210911.0     185.184.230.40  199  3421  0911
13  2308024432  19934210912.0     183.154.230.41  199  3421  0912
14  2308024446  19934210913.0     183.184.231.42  199  3421  0913
15  2308024421  19934210914.0     183.154.230.43  199  3421  0914
16  2308024433  19934210915.0     173.184.230.44  199  3421  0915
17  2308024428  19934210916.0      183.184.230.4  199  3421  0916
18  2308024402  19934210917.0      183.184.230.4  199  3421  0917
19  2308024422  19934210918.0      153.144.230.7  199  3421  0918
```
我们看到新表的最后创建的列名都是电话。 
我们应该修改这些列名,再和大表合并
我们可以看到brands的类型是object, name='电话'， 而该列名就是大表的列名。 所以我们修改name值，
就可以得到新的列名。

```Python

brands.name = '移动商'
areas.name = '地区'
tells.name = '号码'
new_data = pd.concat([my_data, brands, areas, tells], axis=1)
```

最后删除电话这一列

```Python
print(new_data.drop(['电话'],axis=1))
[output]
  学号                 IP  移动商    地区    号码
0   2308024241      221.205.98.55  189  2225  4812
1   2308024244    183.184.226.205  135  2225  5003
2   2308024251      221.205.98.55  134  2225  9938
3   2308024249      222.31.51.200  188  2225  6753
4   2308024219       120.207.64.3  189  2225  3721
5   2308024201      222.31.51.200  138  2225  4373
6   2308024347      222.31.59.220  138  2225  4373
7   2308024307  221.205.98.55      133  2225  2452
8   2308024326     183.184.230.38  189  2225  7681
9   2308024320  221.205.98.55      133  2225  2452
10  2308024342     183.184.230.38  189  2225  7681
11  2308024310     183.184.230.39  199  3421  0999
12  2308024435     185.184.230.40  199  3421  0911
13  2308024432     183.154.230.41  199  3421  0912
14  2308024446     183.184.231.42  199  3421  0913
15  2308024421     183.154.230.43  199  3421  0914
16  2308024433     173.184.230.44  199  3421  0915
17  2308024428      183.184.230.4  199  3421  0916
18  2308024402      183.184.230.4  199  3421  0917
19  2308024422      153.144.230.7  199  3421  0918

删除第一行为：
print(new_data.drop([0],axis=0))
```

### 3. 修改记录

1. 个别替换

df.replace('a','b')  # 把a用b进行替换

2. 批量替换

```Python
import pandas as pd
# 把作弊， 和缺考统统替换为0
df = pd.read_csv(r'd:\textfiles\rz.csv', delimiter=',')
df = df.replace(['作弊', '缺考'], 0)
print(df)
```

3. 特定替换

```Python
# replace({'列名'：'该列的某一单元内容','列名'：'该列的某一单元内容','列名'：'该列的某一单元内容'},需替换的内容)
```

4. 多值替换

```Python
df = df.replace(['作弊', '缺考'], ['偷看', '没来']) ([被替换的词语列表],[替换新的词语列表])
```



## 3.数据交换

### 1. 交换行

```Python
reindex=[1,2,0,3,5,7,9,11,13,15,17,19,4,6,8,10,12,14,16,18,20]
print(df)
df = df.reindex(reindex)
print(df)
```

### 2. 交换列


```Python
import pandas as pd
dt = pd.read_csv(r'k:\rz.csv', sep=',')


dt_name = dt['姓名']
dt_id = dt['学号']

dt = dt.drop(columns=['姓名', '学号'], axis=1)

dt.insert(0,dt_name.name,dt_name)# 三个参数 位置， 列名， 该列的具体内容 dt_name可以是元组或列表类型。
print(dt.head())
```

## 4. 数据计算

### 1. 数据合并

用 df_new = concat(df1,df2); 或者 df1.append(df2, ignore_index=True) 来进行追加。


### 2. 追加列

```Python
df['abc']#  abc为新列名
df['abc'] = df_new_list
df['abc']=['1','2','3','4']
@@@ 要注意的是： 如果列要做计算 需要将列的变量类型进行转换：  比如 df['name']=astype(string), df['age']=astype(int)

```

### 3. 追加行

1. 行内容用 字典格式先定义好。
2. 用append进行添加。

```Python
new=pd.DataFrame({'name':'lisa',
                  'gender':'F',
                  'city':'北京',
                  'age':19,
                  'score':100},
                 )   
df1=df1.append(new,ignore_index=True)   # ignore_index=True,表示不按原来的索引，从0开始自动递增
```

# 数据分析
## 基本统计分析

在pandas包中，可以进行基本的统计分析，比如某个变量的最小值、最大值、四分位值、中值等变量。 

### 中心位置

均值(Mean)、中位数(Median)、 众数(Mode) 都可以表示为一组数的中间位置，但表示方法各不相同

Mean：总和/总数
Median: 从小到大排序的中间位置
Mode: 找出最多次出现的数， 如果最多次出现的多个数，则都列出，则返回一个DataFrame类型变量。
@@@ 填入该列出现频次最高的数：df['数分'] = df['数分'].fillna(df['数分'].mode().iloc[0])
另： 描述性统计分析函数： describe。 该函数可以返回均值、标准差、最大值、最小值等信息

```Python
df = pd.read_excel(r'k:\rz.xlsx', sheetname='Sheet2')
print(df.describe())

[output]
                 学号         英语         数分         高代         解几
count  1.000000e+01  10.000000   9.000000   9.000000  10.000000
mean   2.308024e+09  70.700000  60.777778  52.555556  61.600000
std    4.920976e+01   7.273239  10.825638  15.363196  12.429356
min    2.308024e+09  60.000000  40.000000  23.000000  44.000000
25%    2.308024e+09  66.000000  61.000000  47.000000  49.500000
50%    2.308024e+09  70.000000  61.000000  47.000000  64.500000
75%    2.308024e+09  75.250000  69.000000  62.000000  71.000000
max    2.308024e+09  85.000000  72.000000  76.000000  78.000000
Process finished with exit code 0
```

大家想一下为什么会出现下列情况：

```Python
df = pd.read_excel(r'k:\rz.xlsx', sheetname='Sheet2')
print(df)
print(df.mode())

[output]
           学号  姓名  英语    数分    高代  解几
0  2308024241  成龙  76  40.0  23.0  60
1  2308024244  周怡  66  47.0  47.0  44
2  2308024251  张波  85   NaN  45.0  60
3  2308024249  朱浩  65  72.0  62.0  71
4  2308024219  封印  73  61.0  47.0  46
5  2308024201  迟培  60  71.0  76.0  71
6  2308024347  李华  67  61.0  65.0  78
7  2308024307  陈田  76  69.0   NaN  69
8  2308024326  余皓  66  65.0  61.0  71
9  2308024219  封印  73  61.0  47.0  46
             学号   姓名  英语    数分    高代    解几
0  2.308024e+09   封印  66  61.0  47.0  71.0
1           NaN  NaN  73   NaN   NaN   NaN
2           NaN  NaN  76   NaN   NaN   NaN
```

求平均值及其他求值函数可以用下列代码：  @@@ 还记得输出格式化么？？？？

```Python
print(df.describe())
print('np.mean 函数 %f' % (np.mean(df['英语'])))
print('np.average 函数', np.average(df['英语']))
print('DataFrame mean 函数 {0}'.format(df['英语'].mean()))

[output]
np.mean 函数 70.700000
np.average 函数 70.7
DataFrame mean函数 70.7
```

### 分组分析 

#### 聚合(groupby)  
```Python
df.groupby('哪个列聚合')['被统计的列'].一个计算函数()
例子： print(df.groupby('班级')['英语', '体育', '高代'].mean())
[output]
                 英语         体育    高代
班级                                  
23080242  70.833333  73.000000  50.0
23080243  71.000000  60.666667  60.5
23080244  75.000000  75.375000  72.5

df.groupby('哪个列聚合')['被统计的列'].agg({'列别名':np.函数,'列别名':np.函数})
例子：print(df.groupby(by=['性别','班级'])['解几','高代'].agg({'平均分':np.mean,'最高分':np.max,'最低分':np.min}))



[output]
                   平均分            最高分     最低分    
                    解几         高代  解几  高代  解几  高代
性别 班级                                            
女  23080242  45.000000  47.000000  46  47  44  47
   23080243  78.000000  65.333333  79  67  77  64
   23080244  77.500000  72.500000  80  74  75  71
男  23080242  65.500000  51.500000  71  76  60  23
   23080243  66.666667  55.666667  71  66  60  40
   23080244  75.333333  72.500000  83  90  70  60
```
#### 分组分析

```Python
df = pd.read_excel(r'k:\i_nuc.xls', sheetname='Sheet7')
df['总分'] = df['英语']+df['数分']+df['高代']+df['解几']

print(df.head())

[output]
           学号        班级  姓名 性别  英语  体育  军训  数分  高代  解几   总分
0  2308024241  23080242  成龙  男  76  78  77  40  23  60  199
1  2308024244  23080242  周怡  女  66  91  75  47  47  44  204
2  2308024251  23080242  张波  男  85  81  75  45  45  60  235
3  2308024249  23080242  朱浩  男  65  50  80  72  62  71  270
4  2308024219  23080242  封印  女  73  88  92  61  47  46  227

Process finished with exit code 0


groups = [min(df['总分'])-1, 220, 260, max(df['总分'])+1]
# 根据总分， 将成绩分为三档
labels = ['不及格', '及格', '优秀'] 

marks = pd.cut(df['总分'], groups, labels=labels)
# 根据df中的总分，将数据cut为三组， 并且进行分组值(labels)的填写
df['分组']=marks
# 将数据添加到df中形成新列
print(df)
[output]
            学号        班级   姓名 性别  英语  体育  军训  数分  高代  解几   总分   分组
0   2308024241  23080242   成龙  男  76  78  77  40  23  60  199  不及格
1   2308024244  23080242   周怡  女  66  91  75  47  47  44  204  不及格
2   2308024251  23080242   张波  男  85  81  75  45  45  60  235   及格
3   2308024249  23080242   朱浩  男  65  50  80  72  62  71  270   优秀
4   2308024219  23080242   封印  女  73  88  92  61  47  46  227   及格
5   2308024201  23080242   迟培  男  60  50  89  71  76  71  278   优秀
6   2308024347  23080243   李华  女  67  61  84  61  65  78  271   优秀
7   2308024307  23080243   陈田  男  76  79  86  69  40  69  254   及格
8   2308024326  23080243   余皓  男  66  67  85  65  61  71  263   优秀
9   2308024320  23080243   李嘉  女  62   0  90  60  67  77  266   优秀
10  2308024342  23080243  李上初  男  76  90  84  60  66  60  262   优秀
11  2308024310  23080243   郭窦  女  79  67  84  64  64  79  286   优秀
12  2308024435  23080244  姜毅涛  男  77  71   0  61  73  76  287   优秀
13  2308024432  23080244   赵宇  男  74  74  88  68  70  71  283   优秀
14  2308024446  23080244   周路  女  76  80   0  61  74  80  291   优秀
15  2308024421  23080244  林建祥  男  72  72  81  63  90  75  300   优秀
16  2308024433  23080244  李大强  男  79  76  77  78  70  70  297   优秀
17  2308024428  23080244  李侧通  男  64  96  91  69  60  77  270   优秀
18  2308024402  23080244   王慧  女  73  74  93  70  71  75  289   优秀
19  2308024422  23080244  李晓亮  男  85  60  85  72  72  83  312   优秀

Process finished with exit code 0

分别统计分组人数：
print(df.groupby(df['分组'])['分组'].agg({'人数':np.size}))
```


### 精确查找

相当于 select * from user where score > 70 and math > 70

```Python
print(   df[   ( df['解几']>70 ) & ( df['军训']>70 )     ]     )  找出这两列值符合条件的数据 # 数值选择首选

print(df[df['解几'].isin([71, 69])])  找出这两列值符合条件的数据  # 字符串选择首选

print(df[(df['解几'].isin([71, 69])) & (df['体育'].isin([67]))])  多条件 选择


```
###  交叉分析 

@@@ 交叉分析主要分析两组或两组以上变量之间的关系，以交叉表形式进行他们之间的对比分析

```Python
print(df.pivot_table(index=['班级', '姓名']))

[output]
              体育  军训          学号  数分  英语  解几  高代
班级       姓名                                     
23080242 周怡   91  75  2308024244  47  66  44  47
         封印   88  92  2308024219  61  73  46  47
         张波   81  75  2308024251  45  85  60  45
         成龙   78  77  2308024241  40  76  60  23
         朱浩   50  80  2308024249  72  65  71  62
         迟培   50  89  2308024201  71  60  71  76
23080243 余皓   67  85  2308024326  65  66  71  61
         李上初  90  84  2308024342  60  76  60  66
         李华   61  84  2308024347  61  67  78  65
         李嘉    0  90  2308024320  60  62  77  67
         郭窦   67  84  2308024310  64  79  79  64
         陈田   79  86  2308024307  69  76  69  40
23080244 周路   80   0  2308024446  61  76  80  74
         姜毅涛  71   0  2308024435  61  77  76  73
         李侧通  96  91  2308024428  69  64  77  60
         李大强  76  77  2308024433  78  79  70  70
         李晓亮  60  85  2308024422  72  85  83  72
         林建祥  72  81  2308024421  63  72  75  90
         王慧   74  93  2308024402  70  73  75  71
         赵宇   74  88  2308024432  68  74  71  70

```
我们从输出看出，数据进行了分组分列的透视表输出结构

### 相关分析

判断两个变量是否存在关系，最直观的方法就是绘制散点图，看看变量之间是否符合某个规律。


